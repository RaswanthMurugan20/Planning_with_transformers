{"format": "torch", "nodes": [{"name": "embed_timestep", "id": 140171498169648, "class_name": "Embedding(4096, 2)", "parameters": [["weight", [4096, 2]]], "output_shape": [[64, 70, 2]], "num_parameters": [8192]}, {"name": "embed_state", "id": 140171498170032, "class_name": "Linear(in_features=2, out_features=2, bias=True)", "parameters": [["weight", [2, 2]], ["bias", [2]]], "output_shape": [[64, 70, 2]], "num_parameters": [4, 2]}, {"name": "embed_action", "id": 140171498170080, "class_name": "Linear(in_features=1, out_features=2, bias=True)", "parameters": [["weight", [2, 1]], ["bias", [2]]], "output_shape": [[64, 70, 2]], "num_parameters": [2, 2]}, {"name": "embed_rtg", "id": 140171498169984, "class_name": "Linear(in_features=1, out_features=2, bias=True)", "parameters": [["weight", [2, 1]], ["bias", [2]]], "output_shape": [[64, 70, 2]], "num_parameters": [2, 2]}, {"name": "embed_ln", "id": 140171498169600, "class_name": "LayerNorm((2,), eps=1e-05, elementwise_affine=True)", "parameters": [["weight", [2]], ["bias", [2]]], "output_shape": [[64, 210, 2]], "num_parameters": [2, 2]}, {"name": "transformer.0", "id": 140171498169024, "class_name": "Block(\n  (attention): MaskedCausalAttention(\n    (q_net): Linear(in_features=2, out_features=2, bias=True)\n    (k_net): Linear(in_features=2, out_features=2, bias=True)\n    (v_net): Linear(in_features=2, out_features=2, bias=True)\n    (proj_net): Linear(in_features=2, out_features=2, bias=True)\n    (att_drop): Dropout(p=0.1, inplace=False)\n    (proj_drop): Dropout(p=0.1, inplace=False)\n  )\n  (mlp): Sequential(\n    (0): Linear(in_features=2, out_features=8, bias=True)\n    (1): GELU(approximate=none)\n    (2): Linear(in_features=8, out_features=2, bias=True)\n    (3): Dropout(p=0.1, inplace=False)\n  )\n  (ln1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n  (ln2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["attention.q_net.weight", [2, 2]], ["attention.q_net.bias", [2]], ["attention.k_net.weight", [2, 2]], ["attention.k_net.bias", [2]], ["attention.v_net.weight", [2, 2]], ["attention.v_net.bias", [2]], ["attention.proj_net.weight", [2, 2]], ["attention.proj_net.bias", [2]], ["mlp.0.weight", [8, 2]], ["mlp.0.bias", [8]], ["mlp.2.weight", [2, 8]], ["mlp.2.bias", [2]], ["ln1.weight", [2]], ["ln1.bias", [2]], ["ln2.weight", [2]], ["ln2.bias", [2]]], "output_shape": [[64, 210, 2]], "num_parameters": [4, 2, 4, 2, 4, 2, 4, 2, 16, 8, 16, 2, 2, 2, 2, 2]}, {"name": "predict_rtg", "id": 140171498170128, "class_name": "Linear(in_features=2, out_features=1, bias=True)", "parameters": [["weight", [1, 2]], ["bias", [1]]], "output_shape": [[64, 70, 1]], "num_parameters": [2, 1]}, {"name": "predict_state", "id": 140171498170752, "class_name": "Linear(in_features=2, out_features=2, bias=True)", "parameters": [["weight", [2, 2]], ["bias", [2]]], "output_shape": [[64, 70, 2]], "num_parameters": [4, 2]}, {"name": "predict_action.0", "id": 140171498169936, "class_name": "Linear(in_features=2, out_features=1, bias=True)", "parameters": [["weight", [1, 2]], ["bias", [1]]], "output_shape": [[64, 70, 1]], "num_parameters": [2, 1]}], "edges": []}