============================================================
start time: 08-27-15-53
============================================================
device set to: cuda
dataset path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/data/DG3/traj_data_for_model_3.pkl
model save path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
log csv save path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_log_08-27-15-53.csv
***********CHECK: len(self.trajectories) =3150
**** initializing ContGridWorld_v5 environment *****
====================
init:  [19.5 20.5]
start_pos.shape=(2,)
xlim:  100
Umax=1.9990378869066041
Vmax=0.8324810714401253
Umean=0.41962545542847707
Vmean=0.2523411151246392
====================
act_dim = 1
 ---- Visualizing input ----
===== Note: rescaling states to original scale for viz=====
 ---- -------------- ----
****VERIFY: env.target_pos:  [40. 81.]
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. 
  logger.deprecation(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
actions;
 tensor([[[ 0.0440],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0440],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [-1.0674],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000]]])
============================================================
time elapsed: 0:00:10
num of updates: 100
action loss: 6.68125
eval avg reward: -165.00000
eval avg ep len: 66.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:12
num of updates: 200
action loss: 6.48535
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:15
num of updates: 300
action loss: 6.34838
eval avg reward: -173.00000
eval avg ep len: 74.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:18
num of updates: 400
action loss: 6.22916
eval avg reward: -177.00000
eval avg ep len: 78.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:20
num of updates: 500
action loss: 6.10389
eval avg reward: -184.00000
eval avg ep len: 85.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:23
num of updates: 600
action loss: 5.66329
eval avg reward: -192.00000
eval avg ep len: 93.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:26
num of updates: 700
action loss: 3.86307
eval avg reward: -195.00000
eval avg ep len: 96.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:28
num of updates: 800
action loss: 3.75882
eval avg reward: -200.00000
eval avg ep len: 101.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:31
num of updates: 900
action loss: 3.64548
eval avg reward: -120.00000
eval avg ep len: 120.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:33
num of updates: 1000
action loss: 3.53924
eval avg reward: -120.00000
eval avg ep len: 120.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:36
num of updates: 1100
action loss: 3.42494
eval avg reward: -201.00000
eval avg ep len: 102.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:38
num of updates: 1200
action loss: 3.30823
eval avg reward: -184.00000
eval avg ep len: 85.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:41
num of updates: 1300
action loss: 3.19114
eval avg reward: -176.00000
eval avg ep len: 77.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:43
num of updates: 1400
action loss: 3.07874
eval avg reward: -173.00000
eval avg ep len: 74.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:46
num of updates: 1500
action loss: 2.99217
eval avg reward: -171.00000
eval avg ep len: 72.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:49
num of updates: 1600
action loss: 2.87711
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:52
num of updates: 1700
action loss: 2.78289
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:54
num of updates: 1800
action loss: 2.67844
eval avg reward: -168.00000
eval avg ep len: 69.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:00:57
num of updates: 1900
action loss: 2.60194
eval avg reward: -168.00000
eval avg ep len: 69.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:00
num of updates: 2000
action loss: 2.49211
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[0.7196],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.7166],
         [0.7196],
         [0.7196],
         [0.7196],
         [0.7196],
         [0.7196],
         [0.7196],
         [0.7166],
         [0.7166],
         [0.7196],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:03
num of updates: 2100
action loss: 2.40694
eval avg reward: -172.00000
eval avg ep len: 73.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:05
num of updates: 2200
action loss: 2.31481
eval avg reward: -175.00000
eval avg ep len: 76.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:08
num of updates: 2300
action loss: 2.23173
eval avg reward: -179.00000
eval avg ep len: 80.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:10
num of updates: 2400
action loss: 2.15802
eval avg reward: -179.00000
eval avg ep len: 80.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:13
num of updates: 2500
action loss: 2.07589
eval avg reward: -173.00000
eval avg ep len: 74.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:15
num of updates: 2600
action loss: 2.01578
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:18
num of updates: 2700
action loss: 1.94844
eval avg reward: -165.00000
eval avg ep len: 66.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:21
num of updates: 2800
action loss: 1.88055
eval avg reward: -162.00000
eval avg ep len: 63.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:24
num of updates: 2900
action loss: 1.82572
eval avg reward: -160.00000
eval avg ep len: 61.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:26
num of updates: 3000
action loss: 1.78164
eval avg reward: -159.00000
eval avg ep len: 60.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:29
num of updates: 3100
action loss: 1.73481
eval avg reward: -158.00000
eval avg ep len: 59.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:31
num of updates: 3200
action loss: 1.68617
eval avg reward: -157.00000
eval avg ep len: 58.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:34
num of updates: 3300
action loss: 1.64089
eval avg reward: -157.00000
eval avg ep len: 58.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:36
num of updates: 3400
action loss: 1.61183
eval avg reward: -158.00000
eval avg ep len: 59.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:39
num of updates: 3500
action loss: 1.46999
eval avg reward: -158.00000
eval avg ep len: 59.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:41
num of updates: 3600
action loss: 1.14036
eval avg reward: -159.00000
eval avg ep len: 60.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:44
num of updates: 3700
action loss: 1.12085
eval avg reward: -161.00000
eval avg ep len: 62.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:46
num of updates: 3800
action loss: 1.08606
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:49
num of updates: 3900
action loss: 1.07352
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:52
num of updates: 4000
action loss: 1.05225
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6100],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [1.6099],
         [1.6100],
         [1.6099],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:55
num of updates: 4100
action loss: 1.04058
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:01:57
num of updates: 4200
action loss: 1.03858
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:00
num of updates: 4300
action loss: 1.01991
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:02
num of updates: 4400
action loss: 1.00193
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:05
num of updates: 4500
action loss: 0.98336
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:07
num of updates: 4600
action loss: 0.98444
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:10
num of updates: 4700
action loss: 0.96608
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:12
num of updates: 4800
action loss: 0.94795
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:14
num of updates: 4900
action loss: 0.93755
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:17
num of updates: 5000
action loss: 0.93006
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:19
num of updates: 5100
action loss: 0.91580
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:22
num of updates: 5200
action loss: 0.90067
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:24
num of updates: 5300
action loss: 0.89967
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:27
num of updates: 5400
action loss: 0.89252
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:30
num of updates: 5500
action loss: 0.87326
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:32
num of updates: 5600
action loss: 0.86966
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:35
num of updates: 5700
action loss: 0.84732
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:37
num of updates: 5800
action loss: 0.85967
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:40
num of updates: 5900
action loss: 0.84327
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:42
num of updates: 6000
action loss: 0.83311
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6789],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [1.6788],
         [1.6789],
         [1.6788],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:02:45
num of updates: 6100
action loss: 0.82865
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:47
num of updates: 6200
action loss: 0.82658
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:50
num of updates: 6300
action loss: 0.80998
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:52
num of updates: 6400
action loss: 0.79676
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:55
num of updates: 6500
action loss: 0.80145
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:02:57
num of updates: 6600
action loss: 0.78052
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:00
num of updates: 6700
action loss: 0.78932
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:02
num of updates: 6800
action loss: 0.77886
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:05
num of updates: 6900
action loss: 0.75960
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:07
num of updates: 7000
action loss: 0.76691
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:09
num of updates: 7100
action loss: 0.75841
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:12
num of updates: 7200
action loss: 0.74984
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:14
num of updates: 7300
action loss: 0.74710
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:17
num of updates: 7400
action loss: 0.74031
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:19
num of updates: 7500
action loss: 0.73613
eval avg reward: -169.00000
eval avg ep len: 70.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:22
num of updates: 7600
action loss: 0.72854
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:25
num of updates: 7700
action loss: 0.72247
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:27
num of updates: 7800
action loss: 0.72451
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:30
num of updates: 7900
action loss: 0.71302
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:32
num of updates: 8000
action loss: 0.71109
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [1.7073],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:03:35
num of updates: 8100
action loss: 0.70958
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:37
num of updates: 8200
action loss: 0.69813
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:40
num of updates: 8300
action loss: 0.70544
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:43
num of updates: 8400
action loss: 0.69790
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:45
num of updates: 8500
action loss: 0.69629
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:48
num of updates: 8600
action loss: 0.68097
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:50
num of updates: 8700
action loss: 0.69120
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:53
num of updates: 8800
action loss: 0.68424
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:55
num of updates: 8900
action loss: 0.67906
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:03:58
num of updates: 9000
action loss: 0.67570
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:00
num of updates: 9100
action loss: 0.67638
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:03
num of updates: 9200
action loss: 0.66602
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:05
num of updates: 9300
action loss: 0.66822
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:08
num of updates: 9400
action loss: 0.66244
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:10
num of updates: 9500
action loss: 0.66854
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:13
num of updates: 9600
action loss: 0.66446
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:15
num of updates: 9700
action loss: 0.65624
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:18
num of updates: 9800
action loss: 0.65696
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
time elapsed: 0:04:20
num of updates: 9900
action loss: 0.65518
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/src/model_min_dt.py:63: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  weights = torch.matmul(q, k.transpose(2,3)) / math.sqrt(D)
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:285: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:288: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if not torch.isfinite(tensor).all():
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:203: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  tmin = flat.min().item()
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:204: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  tmax = flat.max().item()
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/wandb/wandb_torch.py:239: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},
============================================================
time elapsed: 0:04:23
num of updates: 10000
action loss: 0.65273
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================
finished training!
============================================================
started training at: 08-27-15-53
finished training at: 22-08-27-15-57-41
total training time: 0:04:23
max d4rl score: -1.00000
saved max d4rl score model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53_best.pt
saved last updated model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_dummy_model_08-27-15-53.pt
============================================================