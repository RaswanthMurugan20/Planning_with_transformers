============================================================
start time: 08-29-11-43
============================================================
device set to: cuda
dataset path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/data/DG3/traj_data_for_model_4.pkl
model save path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
log csv save path: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_log_08-29-11-43.csv
***********CHECK: len(self.trajectories) =5000
**** initializing ContGridWorld_v5 environment *****
====================
init:  [19.5 20.5]
start_pos.shape=(2,)
xlim:  100
Umax=1.9990378869066041
Vmax=0.8324810714401253
Umean=0.41962545542847707
Vmean=0.2523411151246392
====================
act_dim = 1
 ---- Visualizing input ----
===== Note: rescaling states to original scale for viz=====
 ---- -------------- ----
****VERIFY: env.target_pos:  [40. 81.]
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. 
  logger.deprecation(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64
  logger.warn(
/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[-0.3455],
         [ 0.7444],
         [-0.2508],
         [-0.3773],
         [-0.8543],
         [-0.3213],
         [-0.7684],
         [-0.7347],
         [-0.4110],
         [-0.7692],
         [-0.4792],
         [-0.4803],
         [ 0.1081],
         [ 0.2813],
         [-0.5446],
         [-0.9612],
         [-0.7571],
         [-0.1371],
         [-0.8811],
         [-0.1075],
         [-0.4797],
         [-0.8559],
         [ 0.4532],
         [ 0.0674],
         [-1.0175],
         [ 0.1886],
         [-0.5067],
         [-0.8626],
         [-0.0394],
         [-0.3052],
         [-0.4616],
         [-0.8749],
         [-0.7739],
         [-0.0064],
         [-0.8403],
         [ 0.6554],
         [-0.4503],
         [-0.3759],
         [-0.3174],
         [ 0.7400],
         [-0.9742],
         [-0.4164],
         [-0.9660],
         [-0.8777],
         [-1.4033],
         [-0.5829],
         [-0.5335],
         [-1.4165],
         [-0.7762],
         [-0.3901],
         [-1.0261],
         [-0.3988],
         [-0.5719],
         [-0.5643],
         [-0.9964],
         [-0.4776],
         [-0.8351],
         [-0.9365],
         [ 0.0173],
         [-0.0033],
         [-0.1039],
         [-0.5503],
         [-0.2231],
         [-0.3321],
         [-1.0849],
         [-0.7550],
         [-1.0413],
         [-0.3139],
         [-0.7334],
         [-0.0030],
         [-0.8331],
         [-1.0074],
         [-0.8712],
         [-0.7801],
         [-0.4658],
         [-0.5454],
         [-1.3672],
         [-0.7305],
         [-0.6780],
         [-0.3926],
         [-0.2436],
         [-0.3378],
         [-1.0941],
         [-0.3366],
         [-0.3994],
         [-0.3704],
         [-0.7293],
         [-0.8262],
         [-0.7755],
         [-0.3957],
         [-1.1105],
         [-0.6075],
         [-0.5040],
         [-1.0275],
         [-0.9784],
         [-0.8172],
         [-0.8665],
         [-0.2865],
         [-0.2995],
         [-0.4604],
         [-0.4973],
         [-0.6011],
         [-1.1199],
         [ 0.0711],
         [-0.9558],
         [-0.8264],
         [-0.1638],
         [-0.5256],
         [-0.6521],
         [-1.1167],
         [-0.7834],
         [-0.6555],
         [-0.6295],
         [-0.6835],
         [-0.6049],
         [-0.2316],
         [-0.3133],
         [-0.9229],
         [-0.8468],
         [-0.5500]]])
============================================================
time elapsed: 0:00:07
num of updates: 100
action loss: 5.12458
eval avg reward: -219.00000
eval avg ep len: 120.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:10
num of updates: 200
action loss: 4.36920
eval avg reward: -219.00000
eval avg ep len: 120.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:12
num of updates: 300
action loss: 3.66167
eval avg reward: -219.00000
eval avg ep len: 120.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:14
num of updates: 400
action loss: 3.02555
eval avg reward: -195.00000
eval avg ep len: 96.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:17
num of updates: 500
action loss: 2.44650
eval avg reward: -178.00000
eval avg ep len: 79.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[ 0.6184],
         [ 1.0285],
         [ 0.6700],
         [ 0.6324],
         [ 0.4050],
         [ 0.6497],
         [ 0.3593],
         [ 0.4632],
         [ 0.5828],
         [ 0.3969],
         [ 0.5720],
         [ 0.4683],
         [ 0.9996],
         [ 0.8820],
         [ 0.4922],
         [ 0.1308],
         [ 0.3763],
         [ 0.6856],
         [-0.2386],
         [ 0.7844],
         [ 0.4229],
         [-0.3136],
         [ 0.9695],
         [ 0.8746],
         [ 0.0300],
         [ 0.8740],
         [ 0.8840],
         [ 0.3483],
         [ 0.9106],
         [ 0.7877],
         [ 0.6880],
         [-0.4616],
         [ 0.4886],
         [ 0.8811],
         [ 0.4536],
         [ 0.9534],
         [ 0.7026],
         [ 0.6841],
         [ 0.9444],
         [ 0.7383],
         [ 0.3801],
         [ 0.6954],
         [ 0.2180],
         [ 0.1149],
         [ 0.1306],
         [ 0.5828],
         [ 0.4542],
         [-1.2645],
         [ 0.5566],
         [ 0.7252],
         [ 0.4019],
         [ 0.7498],
         [ 0.7068],
         [ 0.6450],
         [ 0.3562],
         [ 0.7811],
         [ 0.4960],
         [ 0.4775],
         [ 0.9287],
         [ 0.9750],
         [ 0.8493],
         [ 0.9612],
         [ 0.9908],
         [ 0.8708],
         [-0.3223],
         [ 0.5441],
         [ 0.2970],
         [ 0.7195],
         [ 0.6076],
         [ 0.8581],
         [-0.1728],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000],
         [ 0.0000]]])
============================================================
time elapsed: 0:00:20
num of updates: 600
action loss: 1.92357
eval avg reward: -170.00000
eval avg ep len: 71.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:22
num of updates: 700
action loss: 1.48060
eval avg reward: -175.00000
eval avg ep len: 76.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:25
num of updates: 800
action loss: 1.11159
eval avg reward: -176.00000
eval avg ep len: 77.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:27
num of updates: 900
action loss: 0.82587
eval avg reward: -162.00000
eval avg ep len: 63.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:29
num of updates: 1000
action loss: 0.60627
eval avg reward: -157.00000
eval avg ep len: 58.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.3975],
         [1.5063],
         [1.4029],
         [1.4145],
         [1.3534],
         [1.4091],
         [1.2960],
         [1.3720],
         [1.3843],
         [1.3166],
         [1.3900],
         [1.2575],
         [1.5020],
         [1.4674],
         [1.3252],
         [1.0815],
         [1.3222],
         [1.3437],
         [0.8656],
         [1.4407],
         [1.2058],
         [0.7282],
         [1.4763],
         [1.4702],
         [1.2589],
         [1.4445],
         [1.4235],
         [1.2812],
         [1.4780],
         [1.4507],
         [1.4454],
         [0.8133],
         [1.3965],
         [1.4609],
         [1.3783],
         [1.4536],
         [1.4515],
         [1.4135],
         [1.4955],
         [1.3733],
         [1.3413],
         [1.4313],
         [1.2990],
         [0.4865],
         [1.1300],
         [1.3684],
         [1.3926],
         [0.3009],
         [1.3504],
         [1.4530],
         [1.2173],
         [1.4705],
         [1.4318],
         [1.4396],
         [1.2196],
         [1.4962],
         [1.3341],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:00:32
num of updates: 1100
action loss: 0.44248
eval avg reward: -156.00000
eval avg ep len: 57.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:35
num of updates: 1200
action loss: 0.33479
eval avg reward: -158.00000
eval avg ep len: 59.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:37
num of updates: 1300
action loss: 0.27570
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:40
num of updates: 1400
action loss: 0.24688
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:42
num of updates: 1500
action loss: 0.23585
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.5688],
         [1.6513],
         [1.5911],
         [1.6732],
         [1.7131],
         [1.6108],
         [1.4630],
         [1.6070],
         [1.7219],
         [1.7305],
         [1.6583],
         [1.3599],
         [1.4253],
         [1.7331],
         [1.4462],
         [1.6269],
         [1.6799],
         [1.4535],
         [1.1666],
         [1.6192],
         [1.2930],
         [1.1095],
         [1.7739],
         [1.7348],
         [1.5187],
         [1.6298],
         [1.7759],
         [1.7514],
         [1.7485],
         [1.7590],
         [1.6831],
         [1.6680],
         [1.7268],
         [1.7737],
         [1.7416],
         [1.7864],
         [1.7092],
         [1.7651],
         [1.7814],
         [1.7792],
         [1.7415],
         [1.6678],
         [1.6254],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:00:45
num of updates: 1600
action loss: 0.22720
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:47
num of updates: 1700
action loss: 0.22124
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:50
num of updates: 1800
action loss: 0.21527
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:52
num of updates: 1900
action loss: 0.20815
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:00:55
num of updates: 2000
action loss: 0.20213
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4966],
         [1.5742],
         [1.5225],
         [1.6294],
         [1.7121],
         [1.5399],
         [1.3794],
         [1.5282],
         [1.6679],
         [1.7450],
         [1.5426],
         [1.2707],
         [1.2710],
         [1.6742],
         [1.3309],
         [1.7090],
         [1.5792],
         [1.3516],
         [1.0961],
         [1.5354],
         [1.1918],
         [1.0428],
         [1.8233],
         [1.7291],
         [1.4249],
         [1.5872],
         [1.9113],
         [1.8695],
         [1.7842],
         [1.8243],
         [1.7102],
         [1.8121],
         [1.7851],
         [1.8799],
         [1.8216],
         [1.9098],
         [1.7641],
         [1.8620],
         [1.9011],
         [1.9124],
         [1.8229],
         [1.7234],
         [1.6480],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:00:57
num of updates: 2100
action loss: 0.19730
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:00
num of updates: 2200
action loss: 0.19138
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:02
num of updates: 2300
action loss: 0.18504
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:05
num of updates: 2400
action loss: 0.18128
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:07
num of updates: 2500
action loss: 0.17454
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4459],
         [1.5003],
         [1.4678],
         [1.5895],
         [1.7058],
         [1.4859],
         [1.3378],
         [1.4836],
         [1.5860],
         [1.7161],
         [1.4530],
         [1.2110],
         [1.2095],
         [1.5635],
         [1.2566],
         [1.2247],
         [1.4774],
         [1.2759],
         [1.0623],
         [1.4467],
         [1.1429],
         [1.0158],
         [1.8220],
         [1.6727],
         [1.3921],
         [1.5281],
         [2.0122],
         [1.9408],
         [1.7791],
         [1.8550],
         [1.7233],
         [1.8838],
         [1.8540],
         [2.0070],
         [1.9134],
         [2.0338],
         [1.8302],
         [1.9750],
         [2.0205],
         [2.0313],
         [1.9071],
         [1.8047],
         [1.7353],
         [2.0219],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:10
num of updates: 2600
action loss: 0.16936
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:12
num of updates: 2700
action loss: 0.16360
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:14
num of updates: 2800
action loss: 0.15828
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:17
num of updates: 2900
action loss: 0.15226
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:19
num of updates: 3000
action loss: 0.14600
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4092],
         [1.5436],
         [1.4211],
         [1.5635],
         [1.7160],
         [1.4494],
         [1.3245],
         [1.4684],
         [1.5274],
         [1.6986],
         [1.4006],
         [1.1803],
         [1.1872],
         [1.4535],
         [1.2154],
         [1.0205],
         [1.4174],
         [1.2304],
         [1.0777],
         [1.3652],
         [1.1445],
         [1.0501],
         [1.7722],
         [1.5769],
         [1.3941],
         [1.4545],
         [1.8838],
         [1.9187],
         [1.7264],
         [1.8331],
         [1.7208],
         [1.8449],
         [1.9459],
         [2.1502],
         [2.0387],
         [2.1190],
         [1.9108],
         [2.1252],
         [2.0995],
         [2.0955],
         [2.0235],
         [1.9124],
         [1.8796],
         [2.1192],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:22
num of updates: 3100
action loss: 0.13986
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:24
num of updates: 3200
action loss: 0.13323
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:26
num of updates: 3300
action loss: 0.12589
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:29
num of updates: 3400
action loss: 0.11923
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:31
num of updates: 3500
action loss: 0.11207
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.3959],
         [1.7191],
         [1.3857],
         [1.5483],
         [1.7043],
         [1.4318],
         [1.3357],
         [1.4623],
         [1.4835],
         [1.6586],
         [1.3714],
         [1.1773],
         [1.1650],
         [1.3409],
         [1.2034],
         [0.9977],
         [1.3748],
         [1.1965],
         [1.1161],
         [1.2878],
         [1.1688],
         [1.1103],
         [1.6521],
         [1.4518],
         [1.3905],
         [1.3680],
         [1.6396],
         [1.7412],
         [1.6317],
         [1.7442],
         [1.7340],
         [1.7869],
         [1.9972],
         [2.2570],
         [2.1593],
         [2.1571],
         [2.0099],
         [2.2881],
         [2.2102],
         [2.1757],
         [2.1862],
         [2.0651],
         [2.0680],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:33
num of updates: 3600
action loss: 0.10626
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:36
num of updates: 3700
action loss: 0.10035
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:38
num of updates: 3800
action loss: 0.09433
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:40
num of updates: 3900
action loss: 0.08912
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:43
num of updates: 4000
action loss: 0.08442
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4086],
         [1.7914],
         [1.3781],
         [1.5400],
         [1.6649],
         [1.4341],
         [1.3533],
         [1.4543],
         [1.4594],
         [1.6037],
         [1.3640],
         [1.1898],
         [1.1646],
         [1.2837],
         [1.2080],
         [1.0252],
         [1.3518],
         [1.1815],
         [1.1361],
         [1.2492],
         [1.1723],
         [1.1485],
         [1.5153],
         [1.3645],
         [1.3615],
         [1.3179],
         [1.4743],
         [1.6055],
         [1.5675],
         [1.6608],
         [1.7516],
         [1.7914],
         [1.9570],
         [2.1915],
         [2.1272],
         [2.1378],
         [2.1120],
         [2.2934],
         [2.2948],
         [2.2913],
         [2.3989],
         [2.2883],
         [2.3339],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:45
num of updates: 4100
action loss: 0.07984
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:48
num of updates: 4200
action loss: 0.07656
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:50
num of updates: 4300
action loss: 0.07287
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:52
num of updates: 4400
action loss: 0.07014
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:01:55
num of updates: 4500
action loss: 0.06738
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4332],
         [1.8245],
         [1.3975],
         [1.5589],
         [1.6575],
         [1.4557],
         [1.3708],
         [1.4583],
         [1.4560],
         [1.5792],
         [1.3627],
         [1.1924],
         [1.1655],
         [1.2770],
         [1.2021],
         [1.0165],
         [1.3326],
         [1.1653],
         [1.1275],
         [1.2419],
         [1.1520],
         [1.1539],
         [1.4450],
         [1.3385],
         [1.3316],
         [1.2891],
         [1.4135],
         [1.5476],
         [1.5652],
         [1.6590],
         [1.7572],
         [1.7988],
         [1.9626],
         [2.1086],
         [2.0886],
         [2.0920],
         [2.1925],
         [2.2579],
         [2.2700],
         [2.3351],
         [2.4644],
         [2.4701],
         [2.5799],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:01:57
num of updates: 4600
action loss: 0.06517
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:00
num of updates: 4700
action loss: 0.06339
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:02
num of updates: 4800
action loss: 0.06140
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:04
num of updates: 4900
action loss: 0.05994
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:06
num of updates: 5000
action loss: 0.05848
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4531],
         [1.8094],
         [1.4136],
         [1.5790],
         [1.6610],
         [1.4734],
         [1.3858],
         [1.4620],
         [1.4512],
         [1.5639],
         [1.3569],
         [1.1926],
         [1.1665],
         [1.2703],
         [1.1916],
         [1.0239],
         [1.3116],
         [1.1546],
         [1.1216],
         [1.2331],
         [1.1353],
         [1.1542],
         [1.4068],
         [1.3237],
         [1.3095],
         [1.2729],
         [1.3787],
         [1.5083],
         [1.5744],
         [1.6709],
         [1.7487],
         [1.8093],
         [1.9769],
         [2.0632],
         [2.0956],
         [2.0724],
         [2.2087],
         [2.2626],
         [2.2434],
         [2.3247],
         [2.4692],
         [2.5582],
         [2.7315],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:02:09
num of updates: 5100
action loss: 0.05747
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:12
num of updates: 5200
action loss: 0.05609
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:14
num of updates: 5300
action loss: 0.05498
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:16
num of updates: 5400
action loss: 0.05407
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:18
num of updates: 5500
action loss: 0.05300
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4702],
         [1.8376],
         [1.4240],
         [1.5976],
         [1.6666],
         [1.4870],
         [1.3994],
         [1.4629],
         [1.4427],
         [1.5502],
         [1.3465],
         [1.1900],
         [1.1638],
         [1.2550],
         [1.1777],
         [1.0155],
         [1.2884],
         [1.1439],
         [1.1155],
         [1.2158],
         [1.1204],
         [1.1476],
         [1.3712],
         [1.3014],
         [1.2917],
         [1.2598],
         [1.3549],
         [1.4684],
         [1.5741],
         [1.6677],
         [1.7316],
         [1.8112],
         [1.9756],
         [2.0429],
         [2.0996],
         [2.0685],
         [2.2171],
         [2.2678],
         [2.2345],
         [2.3081],
         [2.4888],
         [2.5983],
         [2.8296],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:02:21
num of updates: 5600
action loss: 0.05198
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:24
num of updates: 5700
action loss: 0.05140
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:26
num of updates: 5800
action loss: 0.05020
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:28
num of updates: 5900
action loss: 0.04948
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:30
num of updates: 6000
action loss: 0.04836
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******* Verify: visualize_op: states.shape= torch.Size([1, 120, 3])
===== Note: rescaling states to original scale for viz=====
****VERIFY: env.target_pos:  [40. 81.]
actions;
 tensor([[[1.4936],
         [1.8357],
         [1.4419],
         [1.6251],
         [1.6787],
         [1.5072],
         [1.4190],
         [1.4679],
         [1.4388],
         [1.5409],
         [1.3408],
         [1.1914],
         [1.1658],
         [1.2443],
         [1.1685],
         [1.0427],
         [1.2699],
         [1.1400],
         [1.1110],
         [1.2017],
         [1.1095],
         [1.1424],
         [1.3414],
         [1.2819],
         [1.2831],
         [1.2544],
         [1.3328],
         [1.4473],
         [1.5741],
         [1.6660],
         [1.7208],
         [1.8071],
         [1.9795],
         [2.0436],
         [2.1059],
         [2.0685],
         [2.2227],
         [2.2732],
         [2.2323],
         [2.3007],
         [2.4995],
         [2.6108],
         [2.8831],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000],
         [0.0000]]])
============================================================
time elapsed: 0:02:33
num of updates: 6100
action loss: 0.04740
eval avg reward: 58.00000
eval avg ep len: 43.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:35
num of updates: 6200
action loss: 0.04708
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
============================================================
time elapsed: 0:02:38
num of updates: 6300
action loss: 0.04611
eval avg reward: 57.00000
eval avg ep len: 44.00000
max score: -1.00000
saving current model at: /home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/log/my_dt_DG3_model_08-29-11-43.pt
******** Verify: state_dim= 3
******** Verify: act_dim= 1
******** Verify: type(running_state)= <class 'numpy.ndarray'>
******** Verify: type(running_state)= <class 'numpy.ndarray'>
Traceback (most recent call last):
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/src/train_model.py", line 368, in <module>
    train('cfg', args, cfg_name, params2_name)
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/src/train_model.py", line 260, in train
    results, op_traj_dict_list = evaluate_on_env(model, device, context_len, env, rtg_target, rtg_scale,
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/src/src_utils.py", line 170, in evaluate_on_env
    _, act_preds, _ = model.forward(timesteps[:,:context_len],
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/src/model_min_dt.py", line 170, in forward
    state_preds = self.predict_state(h[:,2])    # predict next state given r, s, a
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/rohit/Documents/Research/Planning_with_transformers/Decision_transformer/my-dec-transformer/my-dt-venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt