{"format": "torch", "nodes": [{"name": "embed_timestep", "id": 140668825211312, "class_name": "Embedding(4096, 4)", "parameters": [["weight", [4096, 4]]], "output_shape": [[64, 70, 4]], "num_parameters": [16384]}, {"name": "embed_state", "id": 140668825208144, "class_name": "Linear(in_features=3, out_features=4, bias=True)", "parameters": [["weight", [4, 3]], ["bias", [4]]], "output_shape": [[64, 70, 4]], "num_parameters": [12, 4]}, {"name": "embed_action", "id": 140668825207136, "class_name": "Linear(in_features=1, out_features=4, bias=True)", "parameters": [["weight", [4, 1]], ["bias", [4]]], "output_shape": [[64, 70, 4]], "num_parameters": [4, 4]}, {"name": "embed_rtg", "id": 140668825207520, "class_name": "Linear(in_features=1, out_features=4, bias=True)", "parameters": [["weight", [4, 1]], ["bias", [4]]], "output_shape": [[64, 70, 4]], "num_parameters": [4, 4]}, {"name": "embed_ln", "id": 140668825210064, "class_name": "LayerNorm((4,), eps=1e-05, elementwise_affine=True)", "parameters": [["weight", [4]], ["bias", [4]]], "output_shape": [[64, 210, 4]], "num_parameters": [4, 4]}, {"name": "transformer.0", "id": 140668825209536, "class_name": "Block(\n  (attention): MaskedCausalAttention(\n    (q_net): Linear(in_features=4, out_features=4, bias=True)\n    (k_net): Linear(in_features=4, out_features=4, bias=True)\n    (v_net): Linear(in_features=4, out_features=4, bias=True)\n    (proj_net): Linear(in_features=4, out_features=4, bias=True)\n    (att_drop): Dropout(p=0.1, inplace=False)\n    (proj_drop): Dropout(p=0.1, inplace=False)\n  )\n  (mlp): Sequential(\n    (0): Linear(in_features=4, out_features=16, bias=True)\n    (1): GELU(approximate=none)\n    (2): Linear(in_features=16, out_features=4, bias=True)\n    (3): Dropout(p=0.1, inplace=False)\n  )\n  (ln1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n  (ln2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["attention.q_net.weight", [4, 4]], ["attention.q_net.bias", [4]], ["attention.k_net.weight", [4, 4]], ["attention.k_net.bias", [4]], ["attention.v_net.weight", [4, 4]], ["attention.v_net.bias", [4]], ["attention.proj_net.weight", [4, 4]], ["attention.proj_net.bias", [4]], ["mlp.0.weight", [16, 4]], ["mlp.0.bias", [16]], ["mlp.2.weight", [4, 16]], ["mlp.2.bias", [4]], ["ln1.weight", [4]], ["ln1.bias", [4]], ["ln2.weight", [4]], ["ln2.bias", [4]]], "output_shape": [[64, 210, 4]], "num_parameters": [16, 4, 16, 4, 16, 4, 16, 4, 64, 16, 64, 4, 4, 4, 4, 4]}, {"name": "predict_rtg", "id": 140668825207472, "class_name": "Linear(in_features=4, out_features=1, bias=True)", "parameters": [["weight", [1, 4]], ["bias", [1]]], "output_shape": [[64, 70, 1]], "num_parameters": [4, 1]}, {"name": "predict_state", "id": 140669576845520, "class_name": "Linear(in_features=4, out_features=3, bias=True)", "parameters": [["weight", [3, 4]], ["bias", [3]]], "output_shape": [[64, 70, 3]], "num_parameters": [12, 3]}, {"name": "predict_action.0", "id": 140669576846960, "class_name": "Linear(in_features=4, out_features=1, bias=True)", "parameters": [["weight", [1, 4]], ["bias", [1]]], "output_shape": [[64, 70, 1]], "num_parameters": [4, 1]}], "edges": []}